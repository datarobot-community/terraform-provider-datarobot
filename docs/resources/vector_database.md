---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "datarobot_vector_database Resource - datarobot"
subcategory: ""
description: |-
  Vector database
---

# datarobot_vector_database (Resource)

Vector database

## Example Usage

```terraform
resource "datarobot_use_case" "example" {
  name        = "An example use case"
  description = "Description for the example use case"
}

resource "datarobot_dataset_from_file" "example" {
  source_file = "[Path to file to upload]"
  use_case_id = datarobot_use_case.example.id
}

resource "datarobot_vector_database" "example" {
  name        = "An example vector database"
  use_case_id = datarobot_use_case.example.id
  dataset_id  = datarobot_dataset_from_file.example.id
  chunking_parameters = {
    chunk_overlap_percentage = 0
    chunk_size               = 512
    chunking_method          = "recursive"
    embedding_model          = "jinaai/jina-embedding-t-en-v1"
    separators               = ["\n", " "]
  }
}

output "example_id" {
  value       = datarobot_vector_database.example.id
  description = "The id for the example vector database"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `dataset_id` (String) The id of the Vector Database.
- `name` (String) The name of the VectorDatabase.
- `use_case_id` (String) The id of the Use Case.

### Optional

- `chunking_parameters` (Attributes) The chunking parameters for the Model. (see [below for nested schema](#nestedatt--chunking_parameters))

### Read-Only

- `id` (String) The ID of the VectorDatabase.

<a id="nestedatt--chunking_parameters"></a>
### Nested Schema for `chunking_parameters`

Optional:

- `chunk_overlap_percentage` (Number) The percentage of overlap between chunks.
- `chunk_size` (Number) The size of the chunks.
- `chunking_method` (String) The method used to chunk the data.
- `embedding_model` (String) The id of the Embedding Model.
- `is_separator_regex` (Boolean) Whether the separator is a regex.
- `separators` (List of String) The separators used to split the data.
